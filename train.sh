#!/bin/bash

# è®­ç»ƒè„šæœ¬ - ä½¿ç”¨çœŸå®QwenVLæ•°æ®çš„ä½ç§©åˆ†è§£æ¨¡å‹

# é»˜è®¤å‚æ•°
BATCH_SIZE=${1:-64}
EPOCHS=${2:-200}
LR=${3:-0.0001}
RANK=${4:-128}
LAMBDA_B=${5:-0.0001}
LAMBDA_ORTHO=${6:-0.001}
RESULTS_DIR=${7:-"results"}

echo "ğŸš€ å¼€å§‹è®­ç»ƒä½ç§©åˆ†è§£æ¨¡å‹..."
echo "=================================="
echo "è¶…å‚æ•°é…ç½®:"
echo "  Batch Size: $BATCH_SIZE"
echo "  Epochs: $EPOCHS"
echo "  Learning Rate: $LR"
echo "  Rank: $RANK"
echo "  Lambda B: $LAMBDA_B"
echo "  Lambda Ortho: $LAMBDA_ORTHO"
echo "  ç»“æœç›®å½•: $RESULTS_DIR"
echo "=================================="

# æ£€æŸ¥GPUå¯ç”¨æ€§
if command -v nvidia-smi &> /dev/null; then
    echo "ğŸ” æ£€æŸ¥GPUçŠ¶æ€..."
    nvidia-smi --query-gpu=name,memory.total,memory.used --format=csv,noheader,nounits
    echo ""
else
    echo "âš ï¸  æœªæ£€æµ‹åˆ°NVIDIA GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ"
fi

# æ¿€æ´»condaç¯å¢ƒ
echo "ğŸ”§ æ¿€æ´»condaç¯å¢ƒ..."
source ~/anaconda3/etc/profile.d/conda.sh
conda activate mllm

# å¼€å§‹è®­ç»ƒ
echo "ğŸ¯ å¼€å§‹è®­ç»ƒ..."
python train_real_data.py \
    --batch_size $BATCH_SIZE \
    --epochs $EPOCHS \
    --lr $LR \
    --rank $RANK \
    --lambda_B $LAMBDA_B \
    --lambda_ortho $LAMBDA_ORTHO \
    --results_dir $RESULTS_DIR

# æ£€æŸ¥è®­ç»ƒç»“æœ
if [ $? -eq 0 ]; then
    echo "âœ… è®­ç»ƒå®Œæˆï¼"
    echo "ğŸ“Š ç»“æœä¿å­˜åœ¨: $RESULTS_DIR/"
    
    # æ˜¾ç¤ºç»“æœæ–‡ä»¶
    if [ -d "$RESULTS_DIR" ]; then
        echo "ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:"
        ls -la "$RESULTS_DIR/"
    fi
else
    echo "âŒ è®­ç»ƒå¤±è´¥ï¼"
    exit 1
fi

echo "ğŸ‰ è®­ç»ƒè„šæœ¬æ‰§è¡Œå®Œæˆï¼"
