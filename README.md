# ğŸ¯ ä½ç§©åˆ†è§£è®­ç»ƒç³»ç»Ÿï¼ˆåˆå¹¶ç‰ˆ READMEï¼‰

åŸºäº QwenVL3B è§†è§‰ç‰¹å¾çš„ä½ç§©è‡ªé€‚åº”åˆ†è§£ç³»ç»Ÿï¼Œæ”¯æŒå¤šæ¶æ„è®­ç»ƒï¼ˆResMLP / MLPï¼‰ã€SVDåŸºå‡†å¯¹æ¯”ä¸ç©ºé—´å¸ƒå±€å¯è§†åŒ–ï¼Œå¹¶æä¾›æ—©åœä¸å­¦ä¹ ç‡è°ƒåº¦ç­‰å·¥ç¨‹åŒ–èƒ½åŠ›ã€‚æœ¬ README å·²åˆå¹¶å…ˆå‰åˆ†æ•£åœ¨å¤šä¸ª .md æ–‡ä»¶ä¸­çš„ä¿¡æ¯ï¼Œå»é‡ä¸”ä¿æŒä¸ºæœ€æ–°ç‰ˆæœ¬ã€‚

## âœ¨ åŠŸèƒ½æ€»è§ˆ

- **å¤šæ¶æ„**: `ResMLP`ï¼ˆæ®‹å·®å¤šå±‚æ„ŸçŸ¥æœºï¼‰ä¸ `MLP`ï¼ˆçº¯çº¿æ€§å±‚å †å ï¼‰å¯é€‰
- **è®­ç»ƒå¢å¼º**: æ—©åœã€å­¦ä¹ ç‡è°ƒåº¦ï¼ˆReduceLROnPlateauï¼‰ã€æ¢å¤è®­ç»ƒï¼ˆ--resumeï¼‰
- **ç»“æœç®¡ç†**: ä¸åŒæ¶æ„çš„ç»“æœåˆ†ç›®å½•ä¿å­˜ï¼š`results/<arch>/...`
- **æ¯”è¾ƒä¸å¯è§†åŒ–**: SVD å¯¹æ¯”ã€ç©ºé—´å¸ƒå±€å¯è§†åŒ–ï¼ˆ16Ã—16å‰8é€šé“ï¼‰ã€è¯¯å·®çƒ­åŠ›å›¾

## ğŸ› ï¸ ç¯å¢ƒå‡†å¤‡

```bash
conda activate qwen
nvidia-smi
```

## ğŸš€ ä½¿ç”¨æ–¹å¼

### è®­ç»ƒï¼ˆä»å¤´è®­ç»ƒï¼‰
```bash
python train_real_data.py \
  --arch ResMLP \
  --epochs 500 \
  --lr 1e-4 \
  --rank 128 \
  --results_dir results
```

ä½¿ç”¨çº¯ MLP æ¶æ„ï¼š
```bash
python train_real_data.py \
  --arch MLP \
  --epochs 500 \
  --lr 1e-4 \
  --rank 128 \
  --results_dir results
```

ä½¿ç”¨ AdaLoRA æ¶æ„ï¼ˆåŠ¨æ€ç§© + æ­£äº¤å‹å¥½ï¼‰ï¼š
```bash
python train_real_data.py \
  --arch AdaLoRA \
  --epochs 500 \
  --lr 1e-4 \
  --rank 128 \
  --results_dir results \
  --dropout 0.1 \
  --use_rank_allocator \
  --allocator_init_warmup 1000 \
  --allocator_final_warmup 1000 \
  --allocator_mask_interval 20 \
  --allocator_keep_ratio 0.25
# è¯´æ˜ï¼šè®­ç»ƒä¸­ä¼šæŒ‰ä¸Šè¿°è¶…å‚è‡ªåŠ¨æ›´æ–°æ©ç ï¼Œå®ç°åŠ¨æ€ç§©æ§åˆ¶
```

è¯´æ˜ï¼šäº§ç‰©å°†ä¿å­˜åœ¨ `results/<arch>/` ä¸‹ï¼Œä¾‹å¦‚ `results/ResMLP/best_model.pt`ã€‚

### æ¢å¤è®­ç»ƒï¼ˆåŸºäºå½“å‰æ¶æ„çš„ best_model ç»§ç»­ï¼‰
```bash
python train_real_data.py \
  --arch ResMLP \
  --resume \
  --epochs 100 \
  --lr 1e-4 \
  --rank 128 \
  --results_dir results
```

è¯´æ˜ï¼š
- `--resume` ä» `results/<arch>/best_model.pt` è½½å…¥å¹¶ä»ä¸‹ä¸€ epoch ç»§ç»­ã€‚
- æœ¬æ¬¡çš„ `--epochs` æ˜¯è¿½åŠ è®­ç»ƒçš„è½®æ•°ï¼ˆä¸æ˜¯ç»å¯¹ epoch ç¼–å·ï¼‰ã€‚
- å­¦ä¹ ç‡å°†è®°å½•åˆ° `log/logs_æ—¶é—´æˆ³/training.log`ï¼Œè°ƒåº¦å™¨é‡‡ç”¨ `ReduceLROnPlateau` æŒ‰éªŒè¯ MSE è‡ªé€‚åº”è°ƒæ•´ã€‚

### æ¯”è¾ƒï¼ˆSVD vs NNï¼‰
```bash
python compare_svd_nn.py \
  --arch ResMLP \
  --rank 128 \
  --results_dir results
```

å¯¹ AdaLoRA è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œæ¯”è¾ƒï¼š
```bash
python compare_svd_nn.py \
  --arch AdaLoRA \
  --rank 128 \
  --results_dir results
```

### å¯è§†åŒ–ï¼ˆå•å›¾å¯¹æ¯”ï¼‰
```bash
python visualize_svd_nn.py \
  --arch ResMLP \
  --rank 128 \
  --results_dir results \
  --image_idx 0
```

å¯è§†åŒ– AdaLoRAï¼š
```bash
python visualize_svd_nn.py \
  --arch AdaLoRA \
  --rank 128 \
  --results_dir results \
  --image_idx 0
```

### å¸¸è§è·¯å¾„
- æœ€ä½³æ¨¡å‹ï¼š`results/<arch>/best_model.pt`
- è®­ç»ƒå†å²ï¼š`results/<arch>/history.json`
- æ›²çº¿å›¾ï¼š`results/<arch>/train_val_loss_comparison.png`

## ğŸ“‹ å…³é”®å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--arch` | `ResMLP` | æ¨¡å‹æ¶æ„ï¼ˆ`ResMLP` æˆ– `MLP`ï¼‰ |
| `--batch_size` | 8 | è®­ç»ƒæ‰¹æ¬¡å¤§å° |
| `--epochs` | 20 | è®­ç»ƒè½®æ•°æˆ–è¿½åŠ è®­ç»ƒè½®æ•°ï¼ˆå½“ `--resume` æ—¶ï¼‰ |
| `--lr` | 1e-4 | å­¦ä¹ ç‡ |
| `--rank` | 128 | ä½ç§©åˆ†è§£ç§© |
| `--lambda_B` | 1e-4 | BçŸ©é˜µæ­£åˆ™åŒ–æƒé‡ |
| `--lambda_ortho` | 1e-3 | æ­£äº¤æ€§æŸå¤±æƒé‡ |
| `--weight_decay` | 1e-5 | æƒé‡è¡°å‡ |
| `--patience` | 10 | æ—©åœè€å¿ƒ |

## ğŸ“ é¡¹ç›®ç»“æ„ï¼ˆç®€ç‰ˆï¼‰

```
low_rank_image/
â”œâ”€â”€ train_real_data.py         # è®­ç»ƒï¼ˆæ”¯æŒ --arch / --resumeï¼‰
â”œâ”€â”€ compare_svd_nn.py          # SVD vs NN æ¯”è¾ƒï¼ˆæŒ‰æ¶æ„åŠ è½½ï¼‰
â”œâ”€â”€ visualize_svd_nn.py        # å¯è§†åŒ–ï¼ˆæŒ‰æ¶æ„åŠ è½½ï¼‰
â”œâ”€â”€ model.py                   # æ¨¡å‹ï¼šLowRankProjSymmetric / LowRankProjMLP + å·¥å‚æ–¹æ³•
â”œâ”€â”€ qwenvl_dataloader.py       # æ•°æ®åŠ è½½ & ç‰¹å¾ç¼“å­˜
â”œâ”€â”€ svd_baseline.py            # SVDåŸºå‡†
â”œâ”€â”€ train.sh                   # å‘½ä»¤è¡Œè®­ç»ƒè„šæœ¬
â”œâ”€â”€ feature_cache_real/        # 256Ã—2048 ç‰¹å¾ç¼“å­˜
â””â”€â”€ results/
    â”œâ”€â”€ ResMLP/
    â”‚   â”œâ”€â”€ best_model.pt
    â”‚   â”œâ”€â”€ history.json
    â”‚   â””â”€â”€ train_val_loss_comparison.png
    â””â”€â”€ MLP/
        â””â”€â”€ ...
```

## ğŸ”§ æŠ€æœ¯è¦ç‚¹

- è¾“å…¥/è¾“å‡ºï¼š`[batch, 256, 2048]`ï¼Œé‡æ„ `X_hat â‰ˆ A Ã— B`
- ä¼˜åŒ–å™¨ï¼šAdamWï¼›è°ƒåº¦å™¨ï¼šReduceLROnPlateauï¼ˆåŸºäºéªŒè¯ MSEï¼‰
- è®­ç»ƒæ—¥å¿—ï¼š`log/logs_æ—¶é—´æˆ³/`ï¼ˆåŒ…å« configã€trainingã€final_summaryï¼‰
- æ•°æ®é›†ï¼š`textVQA_groundingtask_bbox`ï¼ˆç‰¹å¾ç»´åº¦ `[256, 2048]`ï¼Œå›¾åƒå°ºå¯¸ 448Ã—448ï¼Œpatch 16Ã—16ï¼‰

### AdaLoRA æ¶æ„è¯´æ˜
- æ¨¡å‹åï¼š`AdaptiveLowRankProjAdaLoRA`ï¼ˆå·¥å‚åï¼š`AdaLoRA`/`adaptive_adalora`/`adaptive`ï¼‰
- ç»“æ„ï¼šä½¿ç”¨ `SVDLinear` å †å æ„å»º `row_net` ä¸ `col_net`ï¼›å¼•å…¥å…¨å±€å¯è®­ç»ƒç¼©æ”¾ `lora_E âˆˆ R^{rÃ—1}`ï¼Œåœ¨å‰å‘ä¸­æŒ‰ç§©é€šé“ç¼©æ”¾ `A_raw` å®ç°â€œå¯æ©ç çš„å¥‡å¼‚å€¼â€ï¼›`effective_rank_mask()` ä¸ `current_effective_rank()` ä¾¿äºå¤–éƒ¨ RankAllocator é›†æˆã€‚
- æ­£äº¤æ­£åˆ™ï¼šå»ºè®®å¯¹ `SVDLinear` çš„ `lora_A/lora_B` åšå‚æ•°çº§æ­£äº¤ï¼›å¯é€‰å¯¹ `A` åšæ¿€æ´»çº§æ­£äº¤ï¼ˆ`activation_orth_regu_A`ï¼‰ã€‚

## ğŸ” æ•…éšœæ’é™¤

1. CUDA å†…å­˜ä¸è¶³ï¼šå‡å° `--batch_size`
2. ä¸æ”¶æ•›ï¼šé™ä½å­¦ä¹ ç‡æˆ–å°è¯• `ResMLP` æ¶æ„ï¼Œå¢å¤§ `--epochs`
3. æ— æ³•åŠ è½½æ¨¡å‹ï¼šç¡®è®¤å¯¹åº”æ¶æ„çš„ `results/<arch>/best_model.pt` å·²ç”Ÿæˆ
4. ç‰¹å¾åŠ è½½å¤±è´¥ï¼šæ£€æŸ¥ `feature_cache_real/` æ˜¯å¦å®Œæ•´

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ä¾›å­¦æœ¯ç ”ç©¶ä½¿ç”¨ã€‚

---

æç¤ºï¼šé¦–æ¬¡è¿è¡Œå¯èƒ½è§¦å‘æ¨¡å‹æˆ–æ•°æ®ç¼“å­˜ä¸‹è½½ï¼Œè¯·ç¡®ä¿ç½‘ç»œä¸ç£ç›˜ç©ºé—´å……è¶³ã€‚